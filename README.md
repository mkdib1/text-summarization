
# AIMS
This project aims to perform text summarization using an extractive approach. The objective is to generate summaries by selecting key sentences from the original texts, and to evaluate them using both unsupervised and supervised metrics.  
Additionally, a classification task is performed to assess whether using summaries instead of full texts maintains classification performance across the reference categories.

# DATA
The dataset used is `bbc-news-data`, available here --> ...  
This dataset does not include a reference summary column, which would normally allow for a direct comparison between generated and ground-truth summaries.

# WORK DESCRIPTION
To address this limitation, the following steps were carried out:

- Model training and tuning were conducted in an unsupervised setting after text preprocessing, using the BLANC score to evaluate the quality of summaries generated by different model architectures.
- The same models and tuning procedures were then applied to a second dataset (...) which **does** include reference summaries. The goal was to assess whether BLANC scores align with ROUGE metrics, even though they are evaluated on different datasets.
- The top 3 performing models were used to generate summaries for the `bbc-news-data` dataset.
- Finally, a classification task was performed using the generated summaries to verify whether they preserve the predictive power of the original full texts.


# STRUCTURE
```
|- text_summarization 
|  |- Data/ 					
|     |- bbc-news-data.csv      				# main dataset 
|	  |- cnn_dailymail.csv 						# side dataset to tune models using ROUGE scoring
|        |- output              	# subfolder containing the original bbc-news-data with added summary columns 
|           |- bbc-news-data-summaries.csv  
|        |- results                 # subfolder containing .csv file which report tuning results
|           |- ...
|  |- mod_blanc_tun.py              # .py script to run models whose performance are evaluated using BLANC scoring
|  |- util.py 			# .py script collecting preprocessing and model building functions
|  |- cnn_rouge_tun.ipynb 	# notebook to test models performance among cnn_dailymail ds for supervised evaluation
|  |- .env 						# environment variables setting
|  |- requirements.txt 			# libraries and packages installation guidelines
|  |- README.md 				# this file
```