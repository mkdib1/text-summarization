
# AIMS
This project aims to perform text summarization using an extractive approach. The objective is to generate summaries by selecting key sentences from the original texts, and to evaluate them using both unsupervised and supervised metrics.  
Additionally, a classification task is performed to assess whether using summaries instead of full texts maintains classification performance across the reference categories.

# DATA
The dataset used is the `bbc-news-data`, available as a .zip file here: https://www.kaggle.com/datasets/hgultekin/bbcnewsarchive.
This dataset does not include a reference summary column, which would typically be required for a direct comparison between generated summaries and ground truth.
To enable supervised evaluation of summarization models, a second dataset is used: the `CNN/DailyMail` dataset, available at https://www.kaggle.com/datasets/yatharthgautam123789/cnn-dailymail-3-0-0.

# WORK DESCRIPTION
The following steps were carried out:

- Model training and tuning were conducted in an unsupervised setting after text preprocessing, using the BLANC score to evaluate the quality of summaries generated by different model architectures.
- The same models and tuning procedures were then applied to the second dataset which **does** include reference summaries. The goal was to assess whether BLANC scores align with ROUGE metrics, even though they are evaluated on different datasets.
- The top 3 performing models were used to generate summaries for the `bbc-news-data` dataset.
- Finally, a classification task was performed using the generated summaries to verify whether they preserve the predictive power of the original full texts.


# STRUCTURE
```
|- text_summarization 
|  |- Data/ 					
|     |- bbc-news-data.csv      	# main dataset 
|	  |- cnn_dailymail.csv 			# side dataset
|        |- output              	 
|           |- bbc-news-data-summaries.csv  # main ds with added summary cols
|        |- results                 # subfolder containing .csv file which report tuning results
|           |- blanc_scores.csv     # BLANC scrs results
|           |- rouge_scores.csv     # ROUGE scrs results
|  |- mod_blanc_tun.py              # .py to run models on the main ds and BLANC scoring eval
|  |- util.py 			# .py script collecting preprocessing and model building functions
|  |- cnn_rouge_tun.ipynb 	# notebook to run models on the side ds and ROUGE scoring eval
|  |- .env 						# environment variables setting
|  |- requirements.txt 			# libraries and packages installation guidelines
|  |- README.md 				# this file
```

# USAGE
After cloning the repository from the command line:
```
git clone https://github.com/mkdib1/text-summarization.git
cd text-summarization
```
please install your python virtual environment. Then install the required dependencies:
```
pip -r requirements.txt
```
Finally, set the environmental variable `BASE_DIR` with the full local path pointing to the 'text-summarization/Data' directory.<br>
If you are interested in running the unsupervised tuning procedure, execute:
```
python model_blanc_tun.py
```
If you want to try the supervised tuning procedure, please open `cnn_rouge_tun.ipynb` and runall command
